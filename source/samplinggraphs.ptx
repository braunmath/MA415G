<section xml:id="sec-samplinggraphs">
    <title>Sampling From Graph Models</title>
    
    <p>
        It is frequently the case that we need to generate examples of graphs and networks.
        The random graph models that we have seen so far in this course provide models from which we can draw samples.
        In this section, we will discuss how this is done and what the results are.
        We will begin by sampling from the Erdos-Renyi model of random graphs, which is the random graph model <m>G(n,p)</m> for graphs on <m>n</m> vertices where each edge is included independently with probability <m>p\in (0,1)</m>.
    </p>

    <p>
        There are many subtleties involved in making random choices.
        For example, computationally, how does one generate a "random" value in the interval <m>(0,1)</m>, which is required when determining whether or not an edge is included?
        While we will not go into detail about how this is done, the answer is that for non-secure applications one can use a pseudorandom number generator <url href="https://en.wikipedia.org/wiki/Pseudorandom_number_generator" />.
        For example, in Python a random number in <m>(0,1)</m> is generated using the Mersenne Twister <url href="https://en.wikipedia.org/wiki/Mersenne_Twister" />.
        Using this in combination with Walker's alias method <url href="https://en.wikipedia.org/wiki/Alias_method" /> gives an effective algorithm to sample reasonably randomly from any finite probability distribution.
        For our purposes, we will assume that all of this is correctly implemented in software that is used for experiments.
    </p>


    <algorithm xml:id="alg-ersample">
        <statement>
            <p>
                To sample from the Erdos-Renyi model <m>G(n,p)</m>, for each possible edge in the graph, compute a random value in <m>(0,1)</m> and include the edge if the value is less than <m>p</m>.
            </p>
        </statement>
    </algorithm>

    <exercise>
        <p>
            Does it make sense how a random element is sampled from <m>G(n,p)</m>?
        </p>
    </exercise>

    <p>
        In Sagemath, the command to draw a single random element of <m>G(n,p)</m> is graphs.RandomGNP(n,p).
        Let's do some experiments to see what qualities the resulting graphs have.
        We will first look at the maximum degree using <url href="https://sagecell.sagemath.org/" />.
        The following code plots a histogram of the max degrees for a sample of <m>10,000</m> random graphs drawn from <m>G(50,0.5)</m>, i.e., the uniform distribution on graphs with <m>50</m> vertices.
        <program language="python">
            <input>
                n = 50

                p = 0.5

                sample_size = 10000

                max_degrees = []

                for _ in range(sample_size):
                    G = graphs.RandomGNP(n,p)
                    m = max(G.degree_sequence())
                    max_degrees.append(m)

                show(histogram(max_degrees,bins=n))
            </input>
        </program>
                Observe that the average maximum degree appears to be around <m>32</m>, and if you want to generate a random graph on <m>50</m> vertices with maximum degree less than around <m>25</m>, it might be difficult to find such an object using this method.
    </p>

    <exercise>
        <p>
            Does the above histogram make sense? What implications do you see for sampling from the Erdos-Renyi model?
        </p>
    </exercise>

    <p>
        We can look at a similar situation when we consider the full degree sequence.
        The following code does the following:
        <ol>
            <li>
                <p>
                    Generate <m>1,000</m> random graphs from <m>G(50,0.5)</m>.
                </p>
            </li>
            <li>
                <p>
                    Compute each of their degree sequences sorted from largest to smallest degree.
                </p>
            </li>
            <li>
                <p>
                    Plot the degree sequence as points <m>(0,d_0), (1,d_1), \ldots</m>.
                </p>
            </li>
        </ol>
        Let's see what this looks like by copying the following code into Sagecell and running it.
        <program language="python">
            <input>
n = 50

p = 0.5

sample_size = 1000

degree_sequences = []

for _ in range(sample_size):
    G = graphs.RandomGNP(n,p)
    seq = sorted(G.degree_sequence())
    seq.reverse()
    degree_sequences.append(enumerate(seq))

sum([points(seq) for seq in degree_sequences])

            </input>
        </program>
    </p>
    <p>
        Observe that there is a challenge here, because many of the points corresponding to the degrees are overlapping.
        Thus, we don't have any sense of the density of how many dots are on top of each other.
    </p>

    <exercise>
        <p>
            Discuss the scatterplot above. Does it make sense that some points are "secretly" appearing multiple times on top of each other?
            Where do you think the highest density of repetition of points is?
        </p>
    </exercise>
        
    <p>
        Our response to this challenge of data visualization is to replace each column of dots by a box-and-whiskers plot showing the distribution of the <m>i</m>-th degree in the sequence.
        This is done by the following code, and now we will run this on <m>10,000</m> samples instead of only <m>1,000</m>.
        We will use the pandas and seaborn packages for Python for the data visualization.
        Unfortunately, Sagecell does not provide enough computational support for this, but you can run it on your own at <url href="https://cocalc.com/" /> or through a local Sagemath install.
        <program language="python">
            <input>
import pandas as pd
import seaborn as sns

n = 50

p = 0.5

sample_size = 10000

degree_sequences = []

for _ in range(sample_size):
    G = graphs.RandomGNP(n,p)
    seq = sorted(G.degree_sequence())
    seq.reverse()
    degree_sequences.append(seq)

data = pd.DataFrame(degree_sequences,columns=range(n))
ax = sns.boxplot(data=data)
            </input>
        </program>
        <figure xml:id="fig-er_degreesequence_boxplots">
    <caption>Boxplots for the degree sequence sample.</caption>
    <image source="er_random_degreeseq.png" width="100%"/>
</figure>
Note that for the largest degree (the value of <m>d_0</m> in this code, for which the boxplot is on the far left), the distribution is centered at <m>32</m>, which matches our earlier experimental data.
    These box-and-whisker plots make it clear that the typical degree sequence of a graph sampled from <m>G(50,0.5)</m> passes through a very narrow range of values.
    </p>

    <exercise>
        <p>
            Discuss the box-and-whisker plots above.
            Does it make sense how they were constructed?
            What do the boxes mean, what do the lines mean, and what do the dots mean?
            What extra information does this give you beyond the scatterpoint diagram?
        </p>
    </exercise>

    <p>
        The problem with sampling from an Erdos-Renyi graph is exactly the bias toward certain structural qualities of the graph, which is caused by the underlying binomial distribution.
        This is articulated clearly in the following quote from: Fosdick, Bailey K., Daniel B. Larremore, Joel Nishimura, and Johan Ugander. "Configuring Random Graph Models with Fixed Degree Sequences." SIAM Review 60, no. 2 (2018): 315-55. <url href="http://www.jstor.org/stable/45109418" />
        <figure xml:id="fig-er_quote">
    <caption>Quote regarding sampling from graph models.</caption>
    <image source="graphsamplingquote.png" width="100%"/>
</figure>
    </p>

    <p>
        Thus, to sample graphs that have a degree distribution with a different shape than those produced by Erdos-Renyi graphs, we want to sample from either the configuration model or some variant thereof.
        We will consider some experiments using random graphs with a fixed degree sequence generated with almost the uniform distribution, using an algorithm from: Bayati, M., Kim, J.H. \amp Saberi, A. A Sequential Algorithm for Generating Random Graphs. Algorithmica 58, 860-910 (2010). <url href="https://doi.org/10.1007/s00453-009-9340-1" />
        This is called using the Python Networkx package as random_degree_sequence_graph, via <url href="https://networkx.org/documentation/stable/reference/generated/networkx.generators.degree_seq.random_degree_sequence_graph.html#networkx.generators.degree_seq.random_degree_sequence_graph" />.
        Note that we will no longer be looking at measurements related to the degree sequence, because we have fixed it.
        However, we might now look at something like number of spanning trees.
        The following code will generate <m>5,000</m> random graphs having <m>20</m> vertices of degree <m>3</m>, to evaluate in <url href="https://sagecell.sagemath.org/" />.
        <program language="python">
            <input>
import networkx as nx
import numpy

sample_size = 5000

spanning_tree_counts = []

for _ in range(sample_size):
    G = Graph(nx.random_degree_sequence_graph(20*[3])).copy(immutable=True)
    spanning_tree_counts.append(G.spanning_trees_count())

print("mean is: "+str(numpy.mean(spanning_tree_counts)))
print("standard deviation is: "+str(numpy.std(spanning_tree_counts)))
show(histogram(spanning_tree_counts,bins=30))
            </input>
        </program>
        Note that the average number of spanning trees in a graph in our sample from this model is around <m>3.6-3.8</m> million, and the standard deviation is around <m>0.9-1.0</m> million.
        Thus, there is a wide variety of behavior in terms of the number of spanning trees for graphs with <m>20</m> vertices of degree <m>3</m>, and these are graphs that you will probably never sample using the Erdos-Renyi model.
    </p>

    <exercise>
        <p>
            Discuss the example above. Does it make sense?
        </p>
    </exercise>

    <p>
        One other technique for sampling from connected, loopless, simple (no multiple edges) graphs with a fixed degree sequence is to use <em>Markov Chain Monte Carlo</em> simulation.
        This is done as follows.
        Define the graph of graphs <m>\mathcal{G}(\mathbf{d})</m> to be the directed graph with vertex set all connected graphs with degree sequence <m>\mathbf{d}</m>.
A connected graph <m>G</m> has an arrow to <m>G'</m> in <m>\mathcal{G}(\mathbf{d})</m> if <m>G'</m> is obtained from <m>G</m> via a double-edge swap, i.e., if there exist edges <m>uv</m> and <m>xy</m> in <m>G</m> such that replacing these edges with <m>ux</m> and <m>vy</m> produces <m>G'</m>. 
    </p>
        <figure xml:id="fig-doubleedgeswap">
    <caption>Figure showing a double-edge swap, taking from: Benjamin Braun, Kaitlin Bruegge, Matthew Kahle. "Facets of Random Symmetric Edge Polytopes, Degree Sequences, and Clustering", Discrete Mathematics \amp Theoretical Computer Science, December 11, 2023, vol. 25:2.</caption>
    <image source="doubleedgeswap.png" width="100%"/>
</figure>
<p>
    If performing a particular double-edge swap on <m>G</m> would produce a graph that is outside the space (i.e. the new graph has a loop or multiedge or is disconnected), that swap will correspond to a loop on the vertex <m>G</m> in <m>\mathcal{G}(\mathbf{d})</m>. 
    It is shown in the paper by Fosdick et. al. referenced above that <m>\mathcal{G}(\mathbf{d})</m> is regular, strongly connected, and aperiodic, which means that samples asymptotically obey a uniform distribution.
    </p>

    <p>
        So, to sample using double-edge swaps, one would first create a graph with the degree sequence you want using the reverse of the Havel-Hakimi process.
        Then, one would repeatedly do random double-edge swaps to produce a "random walk" through the graph.
    </p>

    <exercise>
        <p>
            Starting with the Petersen graph, do a sequence (by hand) of double-edge swaps to sample from the space of finite simple graphs with degree sequence <m>(3,3,3,3,3,3,3,3,3,3)</m>.
        </p>
        <figure xml:id="fig-petersenAGAIN">
            <caption>Petersen graph</caption>
            <image source="petersen.png">
            </image>
        </figure>
    </exercise>

    <p>
        The most important take-away from this discussion is:
        <ul>
            <li>
                <p>
                    When you want to randomly sample combinatorial objects, it is equally important to consider the model for your sampling as the objects themselves.
                </p>
            </li>
        </ul>
        Just because you have one process for producing random objects does not mean that it is the right one <em>for your application</em>.
    </p>
   


</section>