<section xml:id="sec-finiteprobability">
    <title>Finite Probability Spaces and Random Variables</title>
    
    <p>
        Our first task is to clearly define what we mean when we talk about likelihood of an event occurring.
    </p>

    <definition xml:id="def-finiteprobabilityspace">
        <statement>
            <p>
                Let <m>\Omega</m> be a finite set.
		We refer to the elements of <m>\Omega</m> as <em>events</em>.
		A <em>probability distribution</em> on <m>\Omega</m> is a function
		<me>
		P:\Omega\mapsto \mathbb{R}_{\geq 0}
		</me>
		such that 
		<me>
		\sum_{x\in \Omega}P(x)=1 \, .
		</me>
		Given a finite set <m>\Omega</m> together with a probability distribution <m>P</m>, we call the pair <m>(\Omega,P)</m> a <em>finite probability space</em>.
	</p>
		<p>
		We call a subset <m>A\subseteq \Omega</m> an <em>event set</em>, and define the <em>probability of the event set</em> <m>A</m> to be
		<me>
		P(A):=\sum_{x\in A}P(x) \, .
		</me>
		If <m>P(x)=1/|\Omega|</m> for all <m>x\in \Omega</m>, then we call <m>P</m> the <em>uniform distribution</em>.
            </p>
        </statement>
    </definition>

	<example>
		<p>
		Consider the set
<me>
\Omega=\{00,10,01,11\}
</me>
 of binary strings of length two, with the uniform distribution <m>P(x)=1/4</m>.
		The interpretation of this distribution is that if you pick one of the four binarys string of length two at random, you are equally likely to pick any of the four strings -- each will appear <m>1/4</m> of the time.
		</p>
	</example>

		<example>
		<p>
		Consider the set of outcomes from rolling a die, which is the values appearing on the six sides:
<me>
\Omega=\{1,2,3,4,5,6\} \, .
</me>
 The uniform distribution in this case gives <m>P(x)=1/6</m>.
		The interpretation of this distribution is that if you roll a fair die, you are equally likely to roll any of the six sides -- each will appear <m>1/6</m> of the time.
		</p>
	</example>

<example>
<p>
Consider again the set
<me>
\Omega=\{00,10,01,11\}
</me>
 of binary strings of length two, but this time we will use a different probability distribution.
Set
<me>
P_{1/8}(x)=(1/8)^{\text{number of }0\text{'s in }x}(7/8)^{\text{number of }1\text{'s in }x} \, .
</me>
Is this a probability distribution? Let's check!
</p>
<p>
First observe that
  <md>
    <mrow>P_{1/8}(00) \amp =(1/8)^2(7/8)^0</mrow>
    <mrow>P_{1/8}(10)=P_{1/8}(01) \amp =(1/8)^1(7/8)^1</mrow>
	<mrow>P_{1/8}(11) \amp =(1/8)^0(7/8)^2</mrow>
  </md>
and therefore using the binomial theorem we have
<md>
	<mrow> \amp P_{1/8}(00)+P_{1/8}(10)+P_{1/8}(01)+P_{1/8}(11) = </mrow>
	<mrow> \amp (1/8)^2(7/8)^0 + 2(1/8)^1(7/8)^1 + (1/8)^0(7/8)^2 = </mrow>
	<mrow> \amp (1/8+7/8)^2 =</mrow>
	<mrow> \amp 1 \, .</mrow>
</md>

So, this is a probability distribution on <m>\{00,10,01,11\}</m> -- it is one which strongly favors binary strings that contain more <m>1</m>'s.
</p>
</example>

<exercise>
<p>
Let <m>p\in (0,1)</m>.
Prove that if <m>\Omega</m> is the set of all binary strings of length <m>3</m>, the function 
<me>
P_{p}(x)=(p)^{\text{number of }0\text{'s in }x}(1-p)^{\text{number of }1\text{'s in }x} 
</me>
is a probability distribution.
</p>
</exercise>

<p>

The previous exercise is a special case of the following theorem.
</p>

<theorem xml:id="thm-binarybinomialdist">
	<statement>
		<p>
			Let <m>p\in (0,1)</m>.
			If <m>\Omega</m> is the set of all binary strings of length <m>n</m>, the function 
			<me>
			P_{p}(x)=(p)^{\text{number of }0\text{'s in }x}(1-p)^{\text{number of }1\text{'s in }x} 
			</me>
			is a probability distribution called the <em>binomial distribution</em> with parameter <m>p</m>.
		</p>
	</statement>
</theorem>

<proof>
	<p>
		Using the binomial theorem, we have that
		<md>
			<mrow> \sum_{w\in \Omega} [(p)^{\text{number of }0\text{'s in }x}(1-p)^{\text{number of }1\text{'s in }x}] \amp =\sum_{k=0}^n \binom{n}{k}p^k(1-p)^{n-k} </mrow>

			<mrow> \amp = (p+(1-p))^n </mrow>
			<mrow> \amp = 1 \, .</mrow>
		</md>
	</p>
</proof>

<exercise>
<p>
	Discuss the proof above. Does it make sense? Why or why not?
</p>
</exercise>


<exercise>
	<p>
		Explain why the binomial distribution 
		<me>
	P_{p}(w)=(p)^{\text{number of }0\text{'s in }w}(1-p)^{\text{number of }1\text{'s in }w} \, .
	</me>
	on binary strings of length <m>n</m> with parameter <m>p=1/2</m> is the uniform distribution.
	</p>
</exercise>

<definition xml:id="def-randomvariable">
	<statement>
		<p>
			Given a probability distribution <m>P</m> on a finite set <m>\Omega</m>, a <em>random variable</em> is a function <m>X:\Omega\mapsto \mathbb{R}</m>.
			If <m>x\in \Omega</m>, we refer to <m>X(x)</m> as the <em>value</em> of the random variable <m>X</m> on the event <m>x</m>.
		</p>
	</statement>
</definition>

<example>
<p>
Consider again the set <m>\Omega=\{00,10,01,11\}</m> of binary strings of length two, with the uniform distribution.
Define the random variable <m>X:\Omega\mapsto \mathbb{R}</m> by <me>X(00)=0, X(10)=1, X(01)=1, X(11)=2</me>.
The interpretation of this random variable is that <m>X(w)</m> counts the number of <m>1</m>'s in the binary string <m>w</m>.
</p>
</example>

<example>
<p>
Consider again the set of outcomes from rolling a die, which is the values appearing on the six sides: <m>\Omega=\{1,2,3,4,5,6\}</m>, with the uniform distribution.
Define the random variable <m>Y:\Omega\mapsto \mathbb{R}</m> by <me>Y(i)=i</me>.
The interpretation of this random variable is that <m>Y(i)</m> is the value appearing on the side of the die when you roll a <m>i</m>.
</p>
</example>

<example>
<p>
	Consider the set of permutations <m>\Omega=\ss_n</m> with the uniform distribution.
	Let <m>X:\ss_n\mapsto \mathbb{R}</m> be the random variable defined by 
	<me>X(\pi)=\text{number of fixed points of }\pi \, .</me>
	The interpretation of this random variable is that <m>X(\pi)</m> counts the number of fixed points in the permutation <m>\pi</m>.
</p>
</example>

<example>
<p>
	Consider the set of all graphs on <m>n</m> vertices, which we will write <m>\Omega=\mathcal{G}_n</m>, with the uniform distribution.
	Let <m>X:\mathcal{G}_n\mapsto \mathbb{R}</m> be the random variable defined by 
	<me>X(G)=\text{number of spanning trees of }G \, .</me>
	The interpretation of this random variable is that <m>X(G)</m> counts the number of spanning trees in the graph <m>G</m>.
</p>
</example>

<p>
	The key question we want to answer is: given a random variable <m>X</m> on a finite probability space <m>(\Omega,P)</m>, if I pick an element of <m>\Omega</m> according to the distribution <m>P</m>, what is the expected value of <m>X(w)</m>?
</p>

</section>
